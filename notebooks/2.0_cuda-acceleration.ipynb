{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA Acceleration in SpecKit\n",
    "\n",
    "This notebook demonstrates CUDA-accelerated spectral analysis capabilities in SpecKit.\n",
    "\n",
    "CUDA acceleration provides significant speedups for large-scale spectral analysis problems, particularly when processing many segments in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from speckit import SpectrumAnalyzer, compute_spectrum\n",
    "from speckit.core import _CUDA_ENABLED, _NUMBA_ENABLED\n",
    "\n",
    "print(f\"CUDA Available: {_CUDA_ENABLED}\")\n",
    "print(f\"Numba Available: {_NUMBA_ENABLED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Large Test Dataset\n",
    "\n",
    "We'll use a large dataset to demonstrate the performance benefits of CUDA acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10_000_000  # 10 million samples\n",
    "fs = 100.0\n",
    "np.random.seed(42)\n",
    "x = np.random.randn(N)\n",
    "\n",
    "print(f\"Generated {N:,} samples at {fs} Hz sampling rate\")\n",
    "print(f\"Data size: {N * 8 / 1e6:.1f} MB (float64)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Backend Performance\n",
    "\n",
    "Let's compare the performance of different backends (NumPy, Numba, CUDA) on the same dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backends = []\n",
    "if _NUMBA_ENABLED:\n",
    "    backends.append('numba')\n",
    "if _CUDA_ENABLED:\n",
    "    backends.append('cuda')\n",
    "backends.append('numpy')  # Always available\n",
    "\n",
    "times = {}\n",
    "results = {}\n",
    "\n",
    "for backend in backends:\n",
    "    print(f\"\nBenchmarking {backend.upper()} backend...\")\n",
    "    analyzer = SpectrumAnalyzer(\n",
    "        data=x, \n",
    "        fs=fs, \n",
    "        backend=backend,\n",
    "        Jdes=1000, \n",
    "        Kdes=100, \n",
    "        order=1,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    t0 = time.perf_counter()\n",
    "    result = analyzer.compute()\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    \n",
    "    times[backend] = elapsed\n",
    "    results[backend] = result\n",
    "    print(f\"  Completed in {elapsed:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Speedup\n",
    "\n",
    "Compare the speedup achieved by each backend relative to NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "backends_list = list(times.keys())\n",
    "speedups = [times['numpy'] / times[b] for b in backends_list]\n",
    "colors = ['royalblue' if b == 'cuda' else 'tomato' if b == 'numba' else 'gray' for b in backends_list]\n",
    "\n",
    "bars = ax.bar(backends_list, speedups, color=colors, alpha=0.7)\n",
    "ax.set_ylabel('Speedup vs NumPy', fontsize=12)\n",
    "ax.set_title('CUDA Acceleration Speedup', fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, speedup in zip(bars, speedups):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{speedup:.2f}x',\n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\nSpeedup Summary:\")\n",
    "for backend, speedup in zip(backends_list, speedups):\n",
    "    print(f\"  {backend.upper()}: {speedup:.2f}x faster than NumPy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Comparison\n",
    "\n",
    "Verify that CUDA produces identical results to the CPU backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for backend in ['numba', 'cuda']:\n",
    "    if backend in results:\n",
    "        result = results[backend]\n",
    "        result.plot(which='asd', ax=ax, label=f'{backend.upper()} backend', alpha=0.7)\n",
    "\n",
    "ax.set_xlim(0.1, fs/2)\n",
    "ax.set_ylabel(r'Amplitude Spectral Density (units/$\\sqrt{\\mathrm{Hz}}$)', fontsize=12)\n",
    "ax.set_xlabel('Frequency (Hz)', fontsize=12)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_title('Spectrum Comparison: CUDA vs Numba', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Numerical comparison\n",
    "if 'numba' in results and 'cuda' in results:\n",
    "    numba_result = results['numba']\n",
    "    cuda_result = results['cuda']\n",
    "    \n",
    "    # Compare frequencies (should match exactly)\n",
    "    freq_match = np.allclose(numba_result.f, cuda_result.f, rtol=1e-12)\n",
    "    print(f\"Frequency grids match: {freq_match}\")\n",
    "    \n",
    "    # Compare spectra (should match within numerical precision)\n",
    "    asd_match = np.allclose(numba_result.asd, cuda_result.asd, rtol=1e-9, atol=1e-12)\n",
    "    print(f\"ASD values match: {asd_match}\")\n",
    "    \n",
    "    if asd_match:\n",
    "        max_diff = np.max(np.abs(numba_result.asd - cuda_result.asd))\n",
    "        rel_diff = max_diff / np.max(numba_result.asd)\n",
    "        print(f\"Maximum absolute difference: {max_diff:.2e}\")\n",
    "        print(f\"Maximum relative difference: {rel_diff:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices and Recommendations\n",
    "\n",
    "### When to Use CUDA\n",
    "\n",
    "- **Large datasets**: CUDA excels with datasets > 1 million samples\n",
    "- **Many segments**: Best performance when K > 1000 segments\n",
    "- **Batch processing**: Ideal for processing multiple datasets or frequencies\n",
    "- **Production workloads**: When consistent high performance is needed\n",
    "\n",
    "### When CPU is Sufficient\n",
    "\n",
    "- **Small datasets**: For N < 100,000 samples, CPU overhead may dominate\n",
    "- **Interactive work**: For exploratory analysis, CPU latency may be acceptable\n",
    "- **Development/debugging**: Easier to debug CPU code\n",
    "\n",
    "### Memory Management\n",
    "\n",
    "- CUDA automatically manages GPU memory\n",
    "- Large datasets are transferred to GPU only during computation\n",
    "- Memory is freed after computation completes\n",
    "\n",
    "### Backend Selection\n",
    "\n",
    "- Use  for automatic selection (recommended)\n",
    "- Explicitly set  to force GPU usage\n",
    "- Set  or  to force CPU usage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}